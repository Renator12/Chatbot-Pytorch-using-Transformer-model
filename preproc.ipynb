{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-18T16:44:50.486049Z",
     "start_time": "2023-05-18T16:44:50.475400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 30.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in ./venv/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: pathy>=0.10.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.30.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:23:00.755663Z",
     "start_time": "2023-05-18T14:22:53.328209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('movie_conversations.txt.zip','r') as z1:\n",
    "    z1.extractall()\n",
    "with ZipFile('movie_lines.txt.zip','r') as z2:\n",
    "    z2.extractall()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:49:57.366145Z",
     "start_time": "2023-05-18T13:49:57.075260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "corpmovie1='movie_conversations.txt'\n",
    "with open(corpmovie1,'r') as corp1:#conversation numbered\n",
    "    convreader=corp1.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:51:26.265244Z",
     "start_time": "2023-05-18T13:51:26.253120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\\n\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convreader[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:55:28.212944Z",
     "start_time": "2023-05-18T13:55:28.193531Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "lines='movie_lines.txt'\n",
    "with open(lines,'r',errors='replace') as line1:\n",
    "    linereader=line1.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:54:21.652900Z",
     "start_time": "2023-05-18T13:54:21.475343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n',\n 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linereader[0:2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:57:21.634079Z",
     "start_time": "2023-05-18T13:57:21.569393Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#use hashmap to map from lines to  lineid to line\n",
    "linemap={}\n",
    "for val in linereader:\n",
    "    x=val.split('+++$+++')\n",
    "    linemap[x[0]]=x[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:59:29.317399Z",
     "start_time": "2023-05-18T13:59:28.963376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "' They do not!\\n'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linemap[next(iter(linemap))] #example of the value of a sample line of this map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:00:47.960151Z",
     "start_time": "2023-05-18T14:00:47.945581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = \"Hello, how are you today?\"  #delete this\n",
    "\n",
    "# Tokenize the text and remove punctuation\n",
    "tokens = [token.text for token in nlp('HOW ARE YOU') if not token.is_punct]\n",
    "\n",
    "# Print the tokens without punctuation\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "\" But imagine the things he'd say during sex.\\n\""
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linemap = {key.strip(): value for key, value in linemap.items()}\n",
    "linemap['L134']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:40:46.759721Z",
     "start_time": "2023-05-18T14:40:46.630922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "['be', 'you', 'my', 'attorney', 'I', 'be', 'Emil', 'I', 'be', 'insane']"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:36:08.929236Z",
     "start_time": "2023-05-18T14:36:08.888690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "qaarray=[]\n",
    "from ast import literal_eval\n",
    "for val in convreader:\n",
    "    num=literal_eval(val.split('+++$+++')[-1])\n",
    "    for x in range(len(num)):\n",
    "        pair=[]\n",
    "        if x !=len(num)-1:\n",
    "            pair.append([token.lemma_ for token in nlp(linemap[num[x]]) if not token.is_space and not token.is_punct])\n",
    "            pair.append([token.lemma_ for token in nlp(linemap[num[x+1]]) if not token.is_space and not token.is_punct])\n",
    "            qaarray.append(pair)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T15:44:44.213107Z",
     "start_time": "2023-05-18T14:42:19.862428Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "['well',\n 'I',\n 'think',\n 'we',\n 'would',\n 'start',\n 'with',\n 'pronunciation',\n 'if',\n 'that',\n 'be',\n 'okay',\n 'with',\n 'you']"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaarray[0][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T16:14:38.396975Z",
     "start_time": "2023-05-18T16:14:38.382219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "#wordtoindex\n",
    "from collections import Counter\n",
    "wordfrequencycounter=Counter()\n",
    "for x in qaarray:\n",
    "    wordfrequencycounter.update(x[0])#update all question\n",
    "    wordfrequencycounter.update(x[1])#update all answers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T16:16:49.867271Z",
     "start_time": "2023-05-18T16:16:47.717665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "#apply min word freq mask\n",
    "min_words=6\n",
    "allwords=[word for word in wordfrequencycounter.keys() if wordfrequencycounter[word]>min_words]\n",
    "wordmap={key:val+1 for val,key in enumerate(allwords)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:05:54.902598Z",
     "start_time": "2023-05-18T17:05:54.888023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "{'can': 1,\n 'we': 2,\n 'make': 3,\n 'this': 4,\n 'quick': 5,\n 'and': 6,\n 'Andrew': 7,\n 'Barrett': 8,\n 'be': 9,\n 'have': 10,\n 'an': 11,\n 'incredibly': 12,\n 'public': 13,\n 'break-': 14,\n 'up': 15,\n 'on': 16,\n 'the': 17,\n 'again': 18,\n 'well': 19,\n 'I': 20,\n 'think': 21,\n 'would': 22,\n 'start': 23,\n 'with': 24,\n 'if': 25,\n 'that': 26,\n 'okay': 27,\n 'you': 28,\n 'not': 29,\n 'gag': 30,\n 'spit': 31,\n 'part': 32,\n 'please': 33,\n 'then': 34,\n 'how': 35,\n \"'bout\": 36,\n 'try': 37,\n 'out': 38,\n 'some': 39,\n 'french': 40,\n 'cuisine': 41,\n 'Saturday': 42,\n 'Night': 43,\n 'ask': 44,\n 'so': 45,\n 'cute': 46,\n 'what': 47,\n 'your': 48,\n 'name': 49,\n 'forget': 50,\n 'it': 51,\n 'no': 52,\n 'my': 53,\n 'fault': 54,\n 'do': 55,\n 'a': 56,\n 'proper': 57,\n 'introduction': 58,\n 'Cameron': 59,\n 'thing': 60,\n 'at': 61,\n 'mercy': 62,\n 'of': 63,\n 'particularly': 64,\n 'hideous': 65,\n 'breed': 66,\n 'loser': 67,\n 'sister': 68,\n 'date': 69,\n 'until': 70,\n 'she': 71,\n 'seem': 72,\n 'like': 73,\n 'could': 74,\n 'get': 75,\n 'easy': 76,\n 'enough': 77,\n 'why': 78,\n 'Unsolved': 79,\n 'mystery': 80,\n 'use': 81,\n 'to': 82,\n 'really': 83,\n 'popular': 84,\n 'when': 85,\n 'high': 86,\n 'school': 87,\n 'just': 88,\n 'sick': 89,\n 'or': 90,\n 'something': 91,\n 'shame': 92,\n 'Gosh': 93,\n 'only': 94,\n 'find': 95,\n 'Kat': 96,\n 'boyfriend': 97,\n 'let': 98,\n 'see': 99,\n 'ma': 100,\n 'head': 101,\n 'right': 102,\n 'ready': 103,\n 'for': 104,\n 'quiz': 105,\n 'want': 106,\n 'know': 107,\n 'say': 108,\n 'though': 109,\n 'useful': 110,\n 'where': 111,\n 'good': 112,\n 'store': 113,\n 'much': 114,\n 'champagne': 115,\n 'cost': 116,\n 'stuff': 117,\n 'never': 118,\n 'in': 119,\n 'life': 120,\n 'point': 121,\n 'someone': 122,\n 'because': 123,\n 'such': 124,\n 'nice': 125,\n 'one': 126,\n 'French': 127,\n 'our': 128,\n 'little': 129,\n 'A': 130,\n 'Date': 131,\n 'plan': 132,\n 'progress': 133,\n 'there': 134,\n 'might': 135,\n 'mind': 136,\n 'count': 137,\n 'help': 138,\n 'cause': 139,\n 'thug': 140,\n 'obviously': 141,\n 'fail': 142,\n 'ever': 143,\n 'go': 144,\n 'word': 145,\n 'as': 146,\n 'gentleman': 147,\n 'sweet': 148,\n 'hair': 149,\n 'look': 150,\n \"'s\": 151,\n 'Deep': 152,\n 'every': 153,\n 'two': 154,\n 'day': 155,\n 'without': 156,\n 'attachment': 157,\n 'sure': 158,\n 'wanna': 159,\n 'but': 160,\n 'unless': 161,\n 'workin': 162,\n 'going': 163,\n 'he': 164,\n 'picture': 165,\n 'her': 166,\n 'drawer': 167,\n 'pretty': 168,\n 'harbor': 169,\n 'same': 170,\n 'sex': 171,\n 'tendency': 172,\n 'kind': 173,\n 'guy': 174,\n 'who': 175,\n 'all': 176,\n \"'ve\": 177,\n 'hear': 178,\n 'dip': 179,\n 'before': 180,\n 'smoke': 181,\n 'Hi': 182,\n 'work': 183,\n 'tonight': 184,\n 'huh': 185,\n 'believe': 186,\n 'share': 187,\n 'art': 188,\n 'instructor': 189,\n 'fun': 190,\n 'ton': 191,\n 'back': 192,\n 'party': 193,\n 'always': 194,\n 'occupy': 195,\n 'selfish': 196,\n 'any': 197,\n 'light': 198,\n 'extra': 199,\n 'listen': 200,\n 'crap': 201,\n 'endless': 202,\n 'blonde': 203,\n 'babble': 204,\n 'bore': 205,\n 'myself': 206,\n 'thank': 207,\n 'God': 208,\n 'more': 209,\n 'story': 210,\n 'about': 211,\n 'figure': 212,\n 'eventually': 213,\n 'real': 214,\n 'fear': 215,\n 'wear': 216,\n 'kid': 217,\n 'sometimes': 218,\n 'become': 219,\n 'quit': 220,\n 'need': 221,\n 'learn': 222,\n 'lie': 223,\n 'wow': 224,\n 'us': 225,\n 'hope': 226,\n 'they': 227,\n 'change': 228,\n 'here': 229,\n 'Joey': 230,\n 'Great': 231,\n 'drink': 232,\n 'practically': 233,\n 'propose': 234,\n 'mean': 235,\n 'Dr.': 236,\n 'great': 237,\n 'exactly': 238,\n 'relevant': 239,\n 'conversation': 240,\n 'oily': 241,\n 'dry': 242,\n 'different': 243,\n 'More': 244,\n 'Bianca': 245,\n 'highlight': 246,\n 'Dorsey': 247,\n 'include': 248,\n 'door': 249,\n 'opening': 250,\n 'coat': 251,\n 'holding': 252,\n 'wonder': 253,\n 'suppose': 254,\n 'actually': 255,\n 'give': 256,\n 'private': 257,\n 'line': 258,\n 'home': 259,\n 'twenty': 260,\n 'minute': 261,\n 'til': 262,\n 're': 263,\n 'sophomore': 264,\n 'prom': 265,\n 'expensive': 266,\n 'Bogey': 267,\n 'yeah': 268,\n 'Sears': 269,\n 'catalog': 270,\n 'tube': 271,\n 'sock': 272,\n 'gig': 273,\n 'huge': 274,\n 'ad': 275,\n 'Queen': 276,\n 'Harry': 277,\n 'next': 278,\n 'week': 279,\n 'gay': 280,\n 'cruise': 281,\n 'will': 282,\n 'uniform': 283,\n 'Neat': 284,\n 'agent': 285,\n 'shot': 286,\n 'year': 287,\n 'hey': 288,\n 'cheek': 289,\n 'concentrate': 290,\n 'awfully': 291,\n 'hard': 292,\n 'consider': 293,\n 'gym': 294,\n 'class': 295,\n 'talk': 296,\n 'deal': 297,\n 't': 298,\n 'Nowhere': 299,\n 'Daddy': 300,\n 'potential': 301,\n 'smack': 302,\n 'way': 303,\n 'least': 304,\n 'bra': 305,\n 'oh': 306,\n 'normal': 307,\n 'play': 308,\n 'Club': 309,\n 'bother': 310,\n 'night': 311,\n 'freak': 312,\n 'torture': 313,\n 'suck': 314,\n 'ruin': 315,\n 'too': 316,\n 'busy': 317,\n 'bitch': 318,\n 'completely': 319,\n 'wretched': 320,\n 'hedge': 321,\n 'pig': 322,\n 'even': 323,\n 'Shakespeare': 324,\n 'maybe': 325,\n 'friend': 326,\n 'guess': 327,\n 'since': 328,\n 'allow': 329,\n 'should': 330,\n 'obsess': 331,\n 'over': 332,\n 'dead': 333,\n 'now': 334,\n 'tell': 335,\n 'social': 336,\n 'advice': 337,\n 'from': 338,\n 'act': 339,\n 'totally': 340,\n 'welcome': 341,\n 'hate': 342,\n 'sit': 343,\n 'Susie': 344,\n 'High': 345,\n 'School': 346,\n 'care': 347,\n 'firm': 348,\n 'believer': 349,\n 'own': 350,\n 'reason': 351,\n 'else': 352,\n 's': 353,\n 'wish': 354,\n 'luxury': 355,\n 'got': 356,\n 'win': 357,\n 't.': 358,\n '9th': 359,\n 'month': 360,\n 'total': 361,\n 'babe': 362,\n 'everyone': 363,\n 'once': 364,\n 'afterwards': 365,\n 'anymore': 366,\n 'piss': 367,\n 'break': 368,\n 'after': 369,\n 'swear': 370,\n 'anything': 371,\n 'except': 372,\n 'stunning': 373,\n 'display': 374,\n 'decision': 375,\n 'instead': 376,\n 'daddy': 377,\n 'hold': 378,\n 'hostage': 379,\n 'stupid': 380,\n 'repeat': 381,\n 'mistake': 382,\n 'protect': 383,\n 'keep': 384,\n 'lock': 385,\n 'away': 386,\n 'dark': 387,\n 'experience': 388,\n 'trust': 389,\n 'people': 390,\n 'beautiful': 391,\n 'last': 392,\n 'set': 393,\n 'damage': 394,\n 'send': 395,\n 'therapy': 396,\n 'forever': 397,\n 'woman': 398,\n 'complete': 399,\n 'fruit': 400,\n 'loop': 401,\n 'Patrick': 402,\n 'that-': 403,\n 'a.': 404,\n 'upset': 405,\n 'boy': 406,\n 'end': 407,\n 'discussion': 408,\n 'neither': 409,\n 'sleep': 410,\n 'fair': 411,\n 'mutant': 412,\n 'must': 413,\n 'attempt': 414,\n 'small': 415,\n 'study': 416,\n 'group': 417,\n 'otherwise': 418,\n 'orgy': 419,\n 'forbid': 420,\n 'Gloria': 421,\n 'expect': 422,\n 'belly': 423,\n 'promise': 424,\n 'present': 425,\n 'scare': 426,\n 'discuss': 427,\n 'tomorrow': 428,\n 'hot': 429,\n 'rod': 430,\n 'bend': 431,\n 'rule': 432,\n 'whatever': 433,\n 'Fine': 434,\n 'prisoner': 435,\n 'house': 436,\n 'daughter': 437,\n 'possession': 438,\n 'miss': 439,\n 'captain': 440,\n 'oppression': 441,\n 'man': 442,\n 'pleasure': 443,\n 'peg': 444,\n 'fan': 445,\n 'pre': 446,\n 'teen': 447,\n 'button': 448,\n 'ring': 449,\n 'Fan': 450,\n 'couple': 451,\n 'minor': 452,\n 'come': 453,\n 'girl': 454,\n 'tall': 455,\n 'decent': 456,\n 'body': 457,\n 'other': 458,\n 'kinda': 459,\n 'short': 460,\n 'them': 461,\n 'through': 462,\n 'new': 463,\n 'tour': 464,\n 'which': 465,\n 'Dakota': 466,\n 'North': 467,\n 'People': 468,\n 'live': 469,\n 'outnumber': 470,\n 'by': 471,\n 'cow': 472,\n 'many': 473,\n 'old': 474,\n 'Thirty': 475,\n 'thousand': 476,\n 'Most': 477,\n 'evil': 478,\n 'these': 479,\n 'horse': 480,\n 'jack': 481,\n 'off': 482,\n 'Clint': 483,\n 'burn': 484,\n 'pine': 485,\n 'perish': 486,\n 'Stratford': 487,\n 'haircut': 488,\n 'matter': 489,\n 'impossibility': 490,\n 'their': 491,\n 'mother': 492,\n 'grandmother': 493,\n 'gene': 494,\n 'pool': 495,\n 'rarely': 496,\n 'shit': 497,\n 'eat': 498,\n 'grin': 499,\n 'moron': 500,\n 'number': 501,\n 'twelve': 502,\n 'model': 503,\n 'mostly': 504,\n 'regional': 505,\n 'rumor': 506,\n 'big': 507,\n 'mom': 508,\n 'Canada': 509,\n 'sign': 510,\n 'tutor': 511,\n 'chance': 512,\n 'encounter': 513,\n 'herself': 514,\n 'teach': 515,\n 'dazzle': 516,\n 'charm': 517,\n 'fall': 518,\n 'love': 519,\n 'Unlikely': 520,\n 'still': 521,\n 'thrive': 522,\n 'danger': 523,\n 'kidding': 524,\n 'criminal': 525,\n 'state': 526,\n 'trooper': 527,\n 'fire': 528,\n 'felon': 529,\n 'serious': 530,\n 'whack': 531,\n 'sell': 532,\n 'his': 533,\n 'liver': 534,\n 'black': 535,\n 'market': 536,\n 'buy': 537,\n 'speaker': 538,\n 'reputation': 539,\n 'strictly': 540,\n 'list': 541,\n 'side': 542,\n 'those': 543,\n 'few': 544,\n 'client': 545,\n 'Wall': 546,\n 'Street': 547,\n 'involve': 548,\n 'choice': 549,\n 'besides': 550,\n 'enemy': 551,\n 'battle': 552,\n 'position': 553,\n 'power': 554,\n 'pretend': 555,\n 'call': 556,\n 'while': 557,\n 'time': 558,\n 'woo': 559,\n 'golden': 560,\n 'opportunity': 561,\n 'case': 562,\n 'wide': 563,\n 'blow': 564,\n 'bent': 565,\n 'himself': 566,\n 'joy': 567,\n 'ultimate': 568,\n 'kiss': 569,\n 'ass': 570,\n 'smoker': 571,\n 'lung': 572,\n 'cancer': 573,\n 'issue': 574,\n 'favorite': 575,\n 'uncle': 576,\n 'forty': 577,\n 'ear': 578,\n 'band': 579,\n 'already': 580,\n 'Hell': 581,\n 'whole': 582,\n 'extremely': 583,\n 'unfortunate': 584,\n 'maneuver': 585,\n 'hell': 586,\n 'pick': 587,\n 'carry': 588,\n 'm': 589,\n 'humiliate': 590,\n 'sacrifice': 591,\n 'yourself': 592,\n 'altar': 593,\n 'dignity': 594,\n 'score': 595,\n 'scenario': 596,\n 'payroll': 597,\n 'awhile': 598,\n 'non-': 599,\n 'prison': 600,\n 'movie': 601,\n 'type': 602,\n 'retrieve': 603,\n 'certain': 604,\n 'piece': 605,\n 'information': 606,\n 'Miss': 607,\n 'helpful': 608,\n 'Thai': 609,\n 'food': 610,\n 'feminist': 611,\n 'angry': 612,\n 'music': 613,\n 'rock': 614,\n 'noodle': 615,\n 'book': 616,\n 'around': 617,\n 'chick': 618,\n 'instrument': 619,\n 'partial': 620,\n 'don': 621,\n 'decide': 622,\n 'nail': 623,\n 'drunk': 624,\n 'remember': 625,\n 'sun': 626,\n 'direct': 627,\n 'quote': 628,\n 'cool': 629,\n 'makin': 630,\n 'bad': 631,\n 'vintage': 632,\n 'read': 633,\n 'notice': 634,\n 'feature': 635,\n 'spread': 636,\n 'elbow': 637,\n 'tough': 638,\n 'run': 639,\n 'rest': 640,\n 'ya': 641,\n 'goin': 642,\n 'leave': 643,\n 'alone': 644,\n 'leg': 645,\n 'rack': 646,\n 'Sure': 647,\n 'Sparky': 648,\n 'money': 649,\n 'take': 650,\n 'cake': 651,\n 'Verona': 652,\n 'tab': 653,\n 'honor': 654,\n 'pay': 655,\n 'catch': 656,\n 'buck': 657,\n 'thirty': 658,\n 'negotiation': 659,\n 'Fifty': 660,\n 'shell': 661,\n 'fifty': 662,\n 'result': 663,\n 'watch': 664,\n 'trash': 665,\n 'car': 666,\n 'under': 667,\n 'control': 668,\n 'craze': 669,\n 'image': 670,\n 'price': 671,\n 'hundred': 672,\n 'human': 673,\n 'flower': 674,\n 'another': 675,\n 'tux': 676,\n 'Barbie': 677,\n 'n': 678,\n 'Ken': 679,\n 'Hey': 680,\n 'lose': 681,\n 'Nope': 682,\n 'chat': 683,\n 'idea': 684,\n 'interested': 685,\n 'insane': 686,\n 'purpose': 687,\n 'recruit': 688,\n 'job': 689,\n 'helpin': 690,\n 'uh': 691,\n 'bathe': 692,\n 'together': 693,\n 'fuck': 694,\n 'heavily': 695,\n 'invest': 696,\n 'Random': 697,\n 'skid': 698,\n 'Pat': 699,\n 'porn': 700,\n 'incapable': 701,\n 'interesting': 702,\n 'Block': 703,\n 'E': 704,\n 'starve': 705,\n 'very': 706,\n 'slow': 707,\n 'die': 708,\n 'slit': 709,\n 'realize': 710,\n 'fine': 711,\n 'institution': 712,\n 'severely': 713,\n 'lacking': 714,\n 'kill': 715,\n 'William': 716,\n 'beyond': 717,\n 'scope': 718,\n 'teenage': 719,\n 'obsession': 720,\n 'venture': 721,\n 'far': 722,\n 'past': 723,\n 'daytime': 724,\n 'show': 725,\n 'enter': 726,\n 'world': 727,\n 'imagine': 728,\n 'during': 729,\n 'foul': 730,\n 'rage': 731,\n 'fit': 732,\n 'Sarah': 733,\n 'Lawrence': 734,\n 'insist': 735,\n 'male': 736,\n 'dominate': 737,\n 'puke': 738,\n 'frat': 739,\n 'golf': 740,\n 'team': 741,\n 'prove': 742,\n 'appreciate': 743,\n 'effort': 744,\n 'toward': 745,\n 'death': 746,\n 'consume': 747,\n 'precious': 748,\n 'officially': 749,\n 'oppose': 750,\n 'suburban': 751,\n 'activity': 752,\n 'favor': 753,\n 'reject': 754,\n 'commercial': 755,\n 'excess': 756,\n 'sound': 757,\n 'Betty': 758,\n 'Archie': 759,\n 'Veronica': 760,\n 'dress': 761,\n 'anyway': 762,\n 'wrong': 763,\n 'perspective': 764,\n 'statement': 765,\n 'meet': 766,\n 'honey': 767,\n 'full': 768,\n 'hallucination': 769,\n 'doing': 770,\n 'attention': 771,\n 'mission': 772,\n 'Friday': 773,\n 'place': 774,\n '7': 775,\n 'Eleven': 776,\n 'lot': 777,\n 'than': 778,\n 'warrant': 779,\n 'strong': 780,\n 'emotion': 781,\n 'spend': 782,\n 'Dollar': 783,\n 'track': 784,\n 'pony': 785,\n 'flat': 786,\n 'beer': 787,\n 'eye': 788,\n 'hand': 789,\n 'cover': 790,\n 'vomit': 791,\n 'seven': 792,\n 'follow': 793,\n 'laundromat': 794,\n 'Thought': 795,\n 'hi': 796,\n 'talker': 797,\n 'depend': 798,\n 'topic': 799,\n 'whip': 800,\n 'into': 801,\n 'verbal': 802,\n 'frenzy': 803,\n 'excuse': 804,\n 'sort': 805,\n 'getting': 806,\n 'Funny': 807,\n 'down': 808,\n 'concussion': 809,\n 'dog': 810,\n 'wake': 811,\n 'vegetable': 812,\n 'difference': 813,\n 'affection': 814,\n 'blind': 815,\n 'hatred': 816,\n 'tequila': 817,\n 'lay': 818,\n 'above': 819,\n 'jail': 820,\n 'father': 821,\n 'approve': 822,\n 'strike': 823,\n 'permission': 824,\n 'gettin': 825,\n 'dad': 826,\n 'pain': 827,\n 'offense': 828,\n 'copy': 829,\n 'poetry': 830,\n 'reading': 831,\n 'pantie': 832,\n 'twist': 833,\n 'effect': 834,\n 'whatsoever': 835,\n 'reflex': 836,\n 'nothing': 837,\n 'spring': 838,\n 'dickhead': 839,\n 'sunshine': 840,\n 'afraid': 841,\n 'height': 842,\n 'lookin': 843,\n 'angle': 844,\n 'put': 845,\n 'foot': 846,\n 'stayin': 847,\n 'climb': 848,\n 'Partridge': 849,\n 'Family': 850,\n 'ridiculous': 851,\n 'respect': 852,\n 'Chapin': 853,\n 'wit': 854,\n 'soft': 855,\n 'yes': 856,\n 'disappoint': 857,\n 'screw': 858,\n 'State': 859,\n 'duck': 860,\n 'career': 861,\n 'true': 862,\n 'pea': 863,\n 'sexy': 864,\n 'amazingly': 865,\n 'self': 866,\n 'assure': 867,\n 'anyone': 868,\n 'request': 869,\n 'command': 870,\n 'tradition': 871,\n 'create': 872,\n 'drama': 873,\n 'motive': 874,\n 'answer': 875,\n 'question': 876,\n 'company': 877,\n 'convict': 878,\n 'sorry': 879,\n 'grandfather': 880,\n 'stay': 881,\n 'Marilyn': 882,\n 'Manson': 883,\n 'Girl': 884,\n 'grandma': 885,\n 'couch': 886,\n 'Fortune': 887,\n 'adorable': 888,\n 'freshman': 889,\n 'yearbook': 890,\n 'wait': 891,\n 'person': 892,\n 'truly': 893,\n 'payment': 894,\n 'bonus': 895,\n 'Fender': 896,\n 'cash': 897,\n 'asshole': 898,\n 'burger': 899,\n 'object': 900,\n 'grill': 901,\n 'Don': 902,\n 'dare': 903,\n 'u': 904,\n '0': 905,\n 'whose': 906,\n 'diary': 907,\n 'devote': 908,\n 'groom': 909,\n 'tip': 910,\n 'Enough': 911,\n 'insurance': 912,\n 'PMS': 913,\n 'seizure': 914,\n 'punish': 915,\n 'agree': 916,\n 'parent': 917,\n 'eighteen': 918,\n 'five': 919,\n 'East': 920,\n 'Coast': 921,\n 'biker': 922,\n 'sperm': 923,\n 'understand': 924,\n 'hip': 925,\n 'dance': 926,\n 'beat': 927,\n 'rub': 928,\n 'impressed': 929,\n 'admit': 930,\n 'capable': 931,\n 'inning': 932,\n 'bleacher': 933,\n 'able': 934,\n 'game': 935,\n 'Christ': 936,\n 'check': 937,\n 'terrorize': 938,\n 'Ms.': 939,\n 'express': 940,\n 'opinion': 941,\n 'terrorist': 942,\n 'action': 943,\n 'compare': 944,\n 'expression': 945,\n 'today': 946,\n 'event': 947,\n 'quite': 948,\n 'mild': 949,\n 'Bobby': 950,\n 'operation': 951,\n 'maintain': 952,\n 'kick': 953,\n 'ball': 954,\n 'merely': 955,\n 'perceive': 956,\n 'somewhat': 957,\n 'term': 958,\n 'most': 959,\n 'often': 960,\n 'feel': 961,\n 'tired': 962,\n 'breathing': 963,\n 'Cool': 964,\n 'standin': 965,\n 'waitin': 966,\n 'situation': 967,\n 'major': 968,\n 'three': 969,\n 'tit': 970,\n 'speak': 971,\n 'correctly': 972,\n 'pure': 973,\n 'plow': 974,\n 'whoever': 975,\n 'pawn': 976,\n 'tame': 977,\n 'wild': 978,\n 'beast': 979,\n 'non': 980,\n 'prefer': 981,\n 'simply': 982,\n 'alternative': 983,\n 'law': 984,\n 'cozy': 985,\n 'sting': 986,\n 'payin': 987,\n 'pissed': 988,\n 'Sweet': 989,\n 'renew': 990,\n 'thy': 991,\n 'force': 992,\n 'Man': 993,\n 'expose': 994,\n 'lunch': 995,\n 'tooth': 996,\n 'zipper': 997,\n 'touch': 998,\n 'flu': 999,\n 'loss': 1000,\n ...}"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordmap #add unknown tokens for words occuring less than 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:05:55.510473Z",
     "start_time": "2023-05-18T17:05:55.454275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "16081"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordmap)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:05:59.875234Z",
     "start_time": "2023-05-18T17:05:59.854906Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "wordmap['<unk>']=len(wordmap)+1\n",
    "wordmap['<pad>']=0\n",
    "wordmap['<start>']=len(wordmap)+1\n",
    "wordmap['<end>']=len(wordmap)+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:08:19.909494Z",
     "start_time": "2023-05-18T17:08:19.880402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "#export json dictionary\n",
    "import json\n",
    "with open('wordmap.json','w') as j1:\n",
    "    json.dump(wordmap,j1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:08:20.281348Z",
     "start_time": "2023-05-18T17:08:20.240173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "#now tokenize question and answers using our wordmap\n",
    "def tokenizequestion(words,wordmap,maxlenpad=25):\n",
    "    if len(words)>=maxlenpad:\n",
    "        tokenized=[wordmap.get(string,wordmap['<unk>']) for string in words[:maxlenpad-len(words)]]\n",
    "    else:\n",
    "        tokenized=[wordmap.get(string,wordmap['<unk>']) for string in words]+[wordmap['<pad>']]*(maxlenpad-len(words))\n",
    "    return tokenized\n",
    "def tokenizeanswer(words,wordmap,maxlenpad):\n",
    "    if len(words)>=maxlenpad:\n",
    "                tokenized=[wordmap.get(string,wordmap['<unk>']) for string in words[:maxlenpad-len(words)]]\n",
    "                tokenized=[wordmap['<start>']]+tokenized+[wordmap['<end>']]\n",
    "    else:\n",
    "        tokenized=[wordmap['<start>']]+[wordmap.get(string,wordmap['<unk>']) for string in words]+[wordmap['<end>']]+[wordmap['<pad>']]*(maxlenpad-len(words))\n",
    "    return tokenized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:17:51.004798Z",
     "start_time": "2023-05-18T20:17:50.982839Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'do', 'not', 'you', 'tell', 'I']\n"
     ]
    }
   ],
   "source": [
    "maxlenpad=25\n",
    "print((qaarray[90][1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:17:51.498350Z",
     "start_time": "2023-05-18T20:17:51.490730Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:17:52.507293Z",
     "start_time": "2023-05-18T20:17:52.498884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 16086, 16086, 6, 7, 8, 9, 10, 11, 12, 16086, 13, 14, 15, 16, 17, 16086, 18, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print((tokenizequestion(qaarray[0][0],wordmap,maxlenpad)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:17:53.078167Z",
     "start_time": "2023-05-18T20:17:53.070191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "#loop over all qaarray values\n",
    "tokenizedvals=[] #all q and a tokenized\n",
    "for val in qaarray:\n",
    "    q=tokenizequestion(val[0],wordmap,maxlenpad)\n",
    "    a=tokenizeanswer(val[1],wordmap,maxlenpad)\n",
    "    if len(q) and len(a)!=2:\n",
    "        tokenizedvals.append([q,a])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:18:01.650552Z",
     "start_time": "2023-05-18T20:17:54.041668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "#DONE PREPROCESSING.EXPORT THIS\n",
    "with open('tokenizedpair.json','w') as write:\n",
    "    json.dump(tokenizedvals,write)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:18:11.504374Z",
     "start_time": "2023-05-18T20:18:01.647067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "27"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizedvals[25][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:13:22.888487Z",
     "start_time": "2023-05-18T20:13:22.880791Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "218338"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizedvals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:16:49.168088Z",
     "start_time": "2023-05-18T20:16:49.161085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "for x in range(218338):\n",
    "    if(len((tokenizedvals[x][0]))!=25):\n",
    "        print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:17:33.363334Z",
     "start_time": "2023-05-18T20:17:33.231498Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "27"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizedvals[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:13:39.130559Z",
     "start_time": "2023-05-18T20:13:39.118349Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "218338"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizedvals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:13:48.186415Z",
     "start_time": "2023-05-18T20:13:48.167592Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "25"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizedvals[46][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:16:02.285940Z",
     "start_time": "2023-05-18T20:16:02.279638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (218338, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[273], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizedvals\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (218338, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.asarray(tokenizedvals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T20:19:12.507926Z",
     "start_time": "2023-05-18T20:19:11.148430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "with open('pairs.json','w') as pairs:\n",
    "    json.dump(qaarray,pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T23:28:28.561926Z",
     "start_time": "2023-05-18T23:28:24.256786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
