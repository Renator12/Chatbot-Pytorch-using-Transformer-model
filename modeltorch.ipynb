{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-18T23:31:23.308887Z",
     "start_time": "2023-05-18T23:31:23.298499Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.pair=json.load(open('pairs_encoded.json'))\n",
    "        self.length=len(self.pair)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        q=torch.LongTensor(self.pair[index][0])#64 bit computer for my pc.Need more bits to encode\n",
    "        a=torch.LongTensor(self.pair[index][1])\n",
    "        return q,a\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T23:53:58.909407Z",
     "start_time": "2023-05-18T23:53:58.885961Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "outputs": [],
   "source": [
    "trainload=torch.utils.data.DataLoader(Dataset(),batch_size=100,shuffle=True,pin_memory=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:33:32.165884Z",
     "start_time": "2023-05-19T00:33:26.293272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 27])"
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,a=next(iter(trainload))\n",
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:33:32.915375Z",
     "start_time": "2023-05-19T00:33:32.864934Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 25])"
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:33:33.425590Z",
     "start_time": "2023-05-19T00:33:33.403266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 27])"
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:33:34.200076Z",
     "start_time": "2023-05-19T00:33:34.192245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "outputs": [],
   "source": [
    "#masks\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'##checked\n",
    "\n",
    "def mask(question, reply_input, reply_target):\n",
    "\n",
    "    def sub_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        return mask.unsqueeze(0)\n",
    "\n",
    "    question_mask = question!=0\n",
    "    question_mask = question_mask.to(device)\n",
    "    question_mask = question_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n",
    "\n",
    "    reply_input_mask = reply_input!=0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
    "    reply_input_mask = reply_input_mask & sub_mask(reply_input.size(-1)).type_as(reply_input_mask.data)\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n",
    "    reply_target_mask = reply_target!=0              # (batch_size, max_words)\n",
    "\n",
    "    return question_mask, reply_input_mask, reply_target_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:28.025229Z",
     "start_time": "2023-05-19T00:43:28.022901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0.],\n        [1., 1., 0., 0., 0.],\n        [1., 1., 1., 0., 0.],\n        [1., 1., 1., 1., 0.],\n        [1., 1., 1., 1., 1.]])"
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size=5\n",
    "torch.triu(torch.ones(size,size)).transpose(0,1)  #diagonal matrix padding future words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:28.626344Z",
     "start_time": "2023-05-19T00:43:28.581541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ True, False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False])"
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]!=0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:28.985981Z",
     "start_time": "2023-05-19T00:43:28.973967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:29.473126Z",
     "start_time": "2023-05-19T00:43:29.466489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module): ##checked\n",
    "    def __init__(self,size,dim,maxlen=50):\n",
    "        super(Embeddings,self).__init__()\n",
    "        self.dim=dim\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.embed=nn.Embedding(size,dim)\n",
    "        self.positional_encoder= self.create_positional_encoder(maxlen,dim)\n",
    "\n",
    "    def create_positional_encoder(self,maxlen,dim):\n",
    "        positionalencoder=torch.zeros(maxlen,dim).to(device)\n",
    "        for positions in range(maxlen):\n",
    "            for i in range(0,dim,2):\n",
    "                positionalencoder[positions,i]=math.sin(positions/10000**((2*i)/dim))\n",
    "                positionalencoder[positions,i+1]=math.cos(positions/(10000**((2*(i+1))/dim)))\n",
    "            positionalencoder=positionalencoder.unsqueeze(0) #(1,maxlen,dim)\n",
    "            return positionalencoder\n",
    "\n",
    "    def forward(self,words):\n",
    "        embedding=self.embed(words)*math.sqrt(self.dim) #(batch_size,maxwords,dim)\n",
    "        embedding+=self.positional_encoder[:,:embedding.size(1)]\n",
    "        embedding=self.dropout(embedding)\n",
    "        return embedding\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:29.953796Z",
     "start_time": "2023-05-19T00:43:29.927659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "outputs": [],
   "source": [
    "class Multiheadattention(nn.Module): ##checked\n",
    "    def __init__(self,head,dim):\n",
    "        super().__init__()\n",
    "        assert dim % head==0\n",
    "        self.dk=dim//head\n",
    "        self.head=head\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.query=nn.Linear(dim,dim)\n",
    "        self.key=nn.Linear(dim,dim)\n",
    "        self.val=nn.Linear(dim,dim)\n",
    "        self.concatlayer=nn.Linear(dim,dim)\n",
    "    def forward(self,query,key,val,mask):\n",
    "        query=self.query(query) #(batch_size,max_words,512)\n",
    "        key=self.key(key)\n",
    "        val=self.val(val)\n",
    "        query=query.view(query.shape[0],-1,self.head,self.dk).permute(0,2,1,3)\n",
    "        key=key.view(key.shape[0],-1,self.head,self.dk).permute(0,2,1,3)\n",
    "        val=val.view(val.shape[0],-1,self.head,self.dk).permute(0,2,1,3)\n",
    "        #dot product\n",
    "        score=torch.matmul(query,key.permute(0,1,3,2))/math.sqrt(self.dk)\n",
    "        score=score.masked_fill(mask==0,-1e9)\n",
    "        weights=F.softmax(score,dim=-1)\n",
    "        weights=self.dropout(weights)\n",
    "        contxt=torch.matmul(weights,val)\n",
    "        contxt=contxt.permute(0,2,1,3).contiguous().view(contxt.shape[0],-1,self.head * self.dk)\n",
    "        intlayer=self.concatlayer(contxt)\n",
    "        return intlayer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:30.390694Z",
     "start_time": "2023-05-19T00:43:30.380162Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "outputs": [],
   "source": [
    "class forward(nn.Module):##checked\n",
    "    def __init__(self,dim,middim=2048):\n",
    "        super().__init__()\n",
    "        self.fullyconnected1=nn.Linear(dim,middim)\n",
    "        self.fullyconnected2=nn.Linear(middim,dim)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "    def forward(self,x):\n",
    "        output=F.relu(self.fullyconnected1(x))\n",
    "        output=self.fullyconnected2(self.dropout(output))\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:30.835569Z",
     "start_time": "2023-05-19T00:43:30.818241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "outputs": [],
   "source": [
    "#encoder layer\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,dim,head):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.selfmultiheadattn=Multiheadattention(head,dim)\n",
    "        self.feedforward=forward(dim)\n",
    "        self.layernormalization=nn.LayerNorm(dim)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self,embedding,mask):\n",
    "        intlayer=self.dropout(self.selfmultiheadattn(embedding,embedding,embedding,mask))\n",
    "        intlayer=self.layernormalization(intlayer+embedding)\n",
    "        ffout=self.dropout(self.feedforward(intlayer))\n",
    "        enc=self.layernormalization(ffout+intlayer)\n",
    "        return enc\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:31.250406Z",
     "start_time": "2023-05-19T00:43:31.235645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):##checked\n",
    "    def __init__(self,dim,head):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layernormalization=nn.LayerNorm(dim)\n",
    "        self.selfmultiheadattn=Multiheadattention(head,dim)\n",
    "        self.sourcemultiheadattn=Multiheadattention(head,dim)\n",
    "        self.feedforward=forward(dim)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self,embedding,encod,sourcemask,targetmask):\n",
    "        query=self.dropout(self.selfmultiheadattn(embedding,embedding,embedding,targetmask))\n",
    "        query=self.layernormalization(query+embedding)\n",
    "        intlayer=self.dropout( self.sourcemultiheadattn(query,encod,encod,sourcemask))\n",
    "        intlayer=self.layernormalization(intlayer+query)\n",
    "        feedforwardoutput=self.dropout(self.feedforward(intlayer))\n",
    "        decod=self.layernormalization(feedforwardoutput+intlayer)\n",
    "        return decod\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:31.675901Z",
     "start_time": "2023-05-19T00:43:31.645848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "outputs": [],
   "source": [
    "class finaltransformer(nn.Module):\n",
    "    def __init__(self,dim,head,numlayer,wordmap):\n",
    "        super(finaltransformer,self).__init__()\n",
    "        self.dim=dim\n",
    "        self.vocabsize=len(wordmap)\n",
    "        self.embed=Embeddings(self.vocabsize,dim)\n",
    "        self.encod=nn.ModuleList([Encoder(dim,head) for i in range(numlayer)])\n",
    "        self.decod=nn.ModuleList([Decoder(dim,head) for i in range(numlayer)])\n",
    "        self.logits=nn.Linear(dim,self.vocabsize)\n",
    "\n",
    "    def encode(self,sourcewords,sourcemask):\n",
    "        sourceembed=self.embed(sourcewords)\n",
    "        for x in self.encod:\n",
    "            sourceembed=x(sourceembed,sourcemask)\n",
    "        return sourceembed\n",
    "\n",
    "    def decode(self,target_word,target_mask,sourceembed,sourcemask):\n",
    "        targetembed = self.embed(target_word)\n",
    "        for x in self.decod:\n",
    "            targetembed=x(targetembed,sourceembed,sourcemask,target_mask)\n",
    "        return targetembed\n",
    "\n",
    "    def forward(self,sourceword,sourcemask,targetword,targetmask):\n",
    "        encod=self.encode(sourceword,sourcemask)\n",
    "        decod = self.decode(targetword, targetmask, encod, sourcemask)\n",
    "        output = F.log_softmax(self.logits(decod), dim=2)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:32.080959Z",
     "start_time": "2023-05-19T00:43:32.068180Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "outputs": [],
   "source": [
    "class Adamw:\n",
    "    def __init__(self,modelsize,steps,optimizer):\n",
    "        self.modelsize=modelsize\n",
    "        self.steps=steps\n",
    "        self.optimizer=optimizer\n",
    "        self.cstep=0\n",
    "        self.lr=0\n",
    "\n",
    "    def getlr(self):\n",
    "        return self.modelsize**(-0.5) *min(self.cstep**(-0.5),self.cstep*self.steps**(-1.5))\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        self.cstep+=1\n",
    "        lr=self.getlr()\n",
    "        for x in self.optimizer.param_groups:\n",
    "            x['lr']=lr\n",
    "        self.lr=lr\n",
    "        self.optimizer.step()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:32.522459Z",
     "start_time": "2023-05-19T00:43:32.507293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "outputs": [],
   "source": [
    "class Losssmooth(nn.Module):\n",
    "    def __init__(self,size,smoothing):\n",
    "        super().__init__()\n",
    "        self.criterion=nn.KLDivLoss(size_average=False,reduce=False)\n",
    "        self.confidence=1.0-smoothing\n",
    "        self.smooth=smoothing\n",
    "        self.size=size\n",
    "    def forward(self,pred,target,mask):\n",
    "        mask=mask.float()\n",
    "        pred=pred.view(-1,pred.size(-1))\n",
    "        target=target.contiguous().view(-1)\n",
    "        mask=mask.view(-1)\n",
    "        label=pred.data.clone()\n",
    "        label.fill_(self.smooth/(self.size-1))\n",
    "        label.scatter_(1,target.data.unsqueeze(1),self.confidence)\n",
    "        loss=(self.criterion(pred,label))\n",
    "        loss=(loss.sum(1)*mask).sum()/mask.sum()\n",
    "        return loss\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:32.959068Z",
     "start_time": "2023-05-19T00:43:32.944477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "outputs": [],
   "source": [
    "#model creation\n",
    "dim=512\n",
    "head=8\n",
    "numlayer=3\n",
    "epochs=10\n",
    "with open('wordmap.json','r') as read1:\n",
    "    wordmap=json.load(read1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:33.297474Z",
     "start_time": "2023-05-19T00:43:33.274462Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "outputs": [],
   "source": [
    "ourtransformer=finaltransformer(dim=dim,head=head,numlayer=numlayer,wordmap=wordmap)\n",
    "ourtransformer=ourtransformer.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:34.189586Z",
     "start_time": "2023-05-19T00:43:33.746907Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(ourtransformer.parameters(),lr=0,betas=(0.9,0.98),eps=1e-9)\n",
    "ourtransformer_optimizer=Adamw(modelsize=dim,steps=4000,optimizer=optimizer)\n",
    "criterion=Losssmooth(len(wordmap),smoothing=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:34.213552Z",
     "start_time": "2023-05-19T00:43:34.187437Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "outputs": [],
   "source": [
    "def train(trainload,ourtransformer,criterion,epoch):\n",
    "    ourtransformer.train()\n",
    "    losses=0\n",
    "    x=0\n",
    "    for i,(q,a) in enumerate(trainload):\n",
    "        sample=q.shape[0]\n",
    "        q=q.to(device)\n",
    "        a=a.to(device)\n",
    "        a_inp=a[:,:-1]\n",
    "        a_targ=a[:,1:]\n",
    "        question_mask,reply_input_mask,reply_target_mask=mask(q,a_inp,a_targ)\n",
    "        output=ourtransformer(q,question_mask,a_inp,reply_input_mask)\n",
    "        loss=criterion(output,a_targ,reply_target_mask)\n",
    "        ourtransformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        ourtransformer_optimizer.step()\n",
    "        losses+=loss.item()*sample\n",
    "        x+=sample\n",
    "        if i%100==0:\n",
    "            print('Epoch [{}][{}/{}]\\tLoss:{:.3f}'.format(epoch,i,len(trainload),losses/x))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:34.923334Z",
     "start_time": "2023-05-19T00:43:34.918869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "outputs": [],
   "source": [
    "#evaluate\n",
    "def eval(finaltransformer,ques,quesmask,maxlen,wordmap):\n",
    "    revwordmap={v:k for k,v in wordmap.items()}\n",
    "    finaltransformer.eval()\n",
    "    start=wordmap['<start>']\n",
    "    encod=finaltransformer.encode(ques,quesmask)\n",
    "    word=torch.LongTensor([[start]]).to(device) #greedy search\n",
    "    for step in range(maxlen-1):\n",
    "        size=word.shape[0]\n",
    "        targetmask=torch.triu(torch.ones(size,size)).transpose(0,1).type(dtype=torch.uint8)\n",
    "        targetmask=targetmask.to(device).unsqueeze(0)\n",
    "        decod=finaltransformer.decode(word,targetmask,encod,quesmask)\n",
    "        pred=finaltransformer.logit(decod[:,-1])\n",
    "        max1,nextw=torch.max(pred,dim=1)\n",
    "        nextw=nextw.item()\n",
    "        if nextw==wordmap[\"<end>\"]:\n",
    "            break\n",
    "        words=torch.cat([word,torch.LongTensor([[nextw]]).to(device)],dim=1)\n",
    "        words=words.squeeze(0)\n",
    "        words=word.tolist()\n",
    "        sen=[x for x in words if x not in {wordmap['<start>']}]\n",
    "        fullsen=' '.join([revwordmap[sen[x]] for x in range (len(sen))])\n",
    "        return fullsen\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:43:35.387871Z",
     "start_time": "2023-05-19T00:43:35.373467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][0/2217]\tLoss:7.464\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[737], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mourtransformer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     state \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m: epoch, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtransformer\u001B[39m\u001B[38;5;124m'\u001B[39m: ourtransformer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtransformer_optimizer\u001B[39m\u001B[38;5;124m'\u001B[39m: ourtransformer_optimizer}\n\u001B[1;32m      6\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(state, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoint_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(epoch) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.pth.tar\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[734], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(trainload, ourtransformer, criterion, epoch)\u001B[0m\n\u001B[1;32m     13\u001B[0m loss\u001B[38;5;241m=\u001B[39mcriterion(output,a_targ,reply_target_mask)\n\u001B[1;32m     14\u001B[0m ourtransformer_optimizer\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 15\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m ourtransformer_optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     17\u001B[0m losses\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39mloss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;241m*\u001B[39msample\n",
      "File \u001B[0;32m~/PycharmProjects/chatbottransformers/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/chatbottransformers/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    train(trainload, ourtransformer, criterion, epoch)\n",
    "\n",
    "    state = {'epoch': epoch, 'transformer': ourtransformer, 'transformer_optimizer': ourtransformer_optimizer}\n",
    "    torch.save(state, 'checkpoint_' + str(epoch) + '.pth.tar')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T00:48:07.989495Z",
     "start_time": "2023-05-19T00:46:01.893146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T23:09:41.350032Z",
     "start_time": "2023-05-18T23:09:41.328833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
